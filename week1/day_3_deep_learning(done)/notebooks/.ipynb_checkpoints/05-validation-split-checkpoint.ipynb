{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting a Validation Set\n",
    "\n",
    "In PyTorch splitting the data is accomplished by data sampler classes in `data.sampler` form the `torch.utils` package. While in PyTorch we must split the data manually, this is not much harder than what we're used to in sckit-learn.\n",
    "\n",
    "\n",
    "To demonstrate we'll be using the `CIFAR10` dataset and the `SubsetRandomSampler` random sub-sampler class. More information about data samplers can be found [here](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual we're going to use `torchvision.datasets` to extract and transform our data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to a normalized torch.FloatTensor\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                              ])\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_set = datasets.CIFAR10('datasets', train=True,\n",
    "                              download=True, transform=transform)\n",
    "\n",
    "test_set = datasets.CIFAR10('datasets', train=False,\n",
    "                             download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the training data in actual training set and validation set we're going to define a split boundary based on a validation data percentage, as one might expect. We'll then use this boundary to define the two ranges of indexes for training and validation. Finally, we'll use the two ranges to define the appropriate loader objects by using the `SubsetRandomSampler` class.\n",
    "\n",
    "**Note** The data loader `shuffle=True` constructor argument is mutually exclusive with the usage of a sampler. So we can use either one, but not both at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "\n",
    "# how many samples per batch to load\n",
    "batch_size = 16\n",
    "\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_set)\n",
    "indices = list(range(num_train))\n",
    "\n",
    "# suffle indices\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# compute the size of the split in number of images\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "\n",
    "# get indexes for the split\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "    sampler=train_sampler, num_workers=num_workers)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, \n",
    "    sampler=valid_sampler, num_workers=num_workers)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, \n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, now we can get batches of data from the loaders in the usual manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch from the train_loader\n",
    "batch = next(iter(train_loader))\n",
    "images, labels = batch\n",
    "\n",
    "images = images / 2 + 0.5  # unnormalize\n",
    "grid = torchvision.utils.make_grid(images, nrow=int(batch_size/2))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(grid.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch from the train_loader\n",
    "batch = next(iter(valid_loader))\n",
    "images, labels = batch\n",
    "\n",
    "images = images / 2 + 0.5  # unnormalize\n",
    "grid = torchvision.utils.make_grid(images, nrow=int(batch_size/2))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(grid.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch from the train_loader\n",
    "batch = next(iter(test_loader))\n",
    "images, labels = batch\n",
    "\n",
    "images = images / 2 + 0.5  # unnormalize\n",
    "grid = torchvision.utils.make_grid(images, nrow=int(batch_size/2))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(grid.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
